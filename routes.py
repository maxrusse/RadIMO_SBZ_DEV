# Standard library imports
import json
import os
import shutil
from datetime import date, datetime
from functools import wraps
from typing import Any, Callable, Optional

# Third-party imports
from flask import (
    Blueprint,
    jsonify,
    redirect,
    render_template,
    request,
    session,
    url_for,
)
import pandas as pd

# Local imports
from config import (
    APP_CONFIG,
    MODALITY_SETTINGS,
    SKILL_SETTINGS,
    allowed_modalities,
    allowed_modalities_map,
    SKILL_COLUMNS,
    SKILL_TEMPLATES,
    modality_labels,
    MASTER_CSV_PATH,
    selection_logger,
    SKILL_ROSTER_AUTO_IMPORT,
    normalize_modality,
    normalize_skill,
    is_no_overflow
)
from lib import usage_logger
from lib.utils import (
    get_local_now,
    get_next_workday,
    get_weekday_name_german,
    TIME_FORMAT,
    skill_value_to_display,
)
from data_manager import (
    modality_data,
    staged_modality_data,
    global_worker_data,
    lock,
    save_state,
    get_canonical_worker_id,
    load_worker_skill_json,
    save_worker_skill_json,
    build_working_hours_from_medweb,
    build_valid_skills_map,
    build_worker_name_mapping,
    auto_populate_skill_roster,
    load_staged_dataframe,
    backup_dataframe,
    _update_schedule_row,
    _add_worker_to_schedule,
    _delete_worker_from_schedule,
    _add_gap_to_schedule,
    preload_next_workday,
    extract_modalities_from_skill_overrides,
    load_unified_scheduled_into_staged,
)
from state_manager import StateManager
from balancer import (
    get_next_available_worker,
    update_global_assignment,
    get_global_assignments,
    get_global_weighted_count,
    get_modality_weighted_count,
    BALANCER_SETTINGS
)

# Create Blueprint
routes = Blueprint('routes', __name__)

# -----------------------------------------------------------
# Helpers for Routes
# -----------------------------------------------------------

def _format_time(value: Any) -> str:
    if pd.notnull(value):
        return value.strftime(TIME_FORMAT)
    return ''


def _parse_tasks(value: Any) -> list[str]:
    if isinstance(value, list):
        return value
    if isinstance(value, str) and value:
        return [task.strip() for task in value.split(',') if task.strip()]
    return []


def _get_counts_for_hours(row: pd.Series, has_column: bool) -> bool:
    if not has_column:
        return True
    value = row.get('counts_for_hours', True)
    if pd.isna(value):
        return True
    return bool(value)


def _df_to_api_response(df: pd.DataFrame) -> list[dict[str, Any]]:
    if df is None or df.empty:
        return []

    data: list[dict[str, Any]] = []
    columns = df.columns
    has_gaps = 'gaps' in columns
    has_counts_for_hours = 'counts_for_hours' in columns
    has_manual = 'is_manual' in columns
    for idx, row in df.iterrows():
        worker_data = {
            'row_index': int(idx),
            'PPL': row['PPL'],
            'start_time': _format_time(row.get('start_time')),
            'end_time': _format_time(row.get('end_time')),
            'Modifier': float(row.get('Modifier', 1.0)) if pd.notnull(row.get('Modifier')) else 1.0,
        }

        if has_gaps:
            gaps_value = row.get('gaps', None)
            worker_data['gaps'] = None if pd.isna(gaps_value) else gaps_value

        for skill in SKILL_COLUMNS:
            worker_data[skill] = skill_value_to_display(row.get(skill, None))

        worker_data['tasks'] = _parse_tasks(row.get('tasks', ''))
        worker_data['counts_for_hours'] = _get_counts_for_hours(row, has_counts_for_hours)

        if has_manual:
            worker_data['is_manual'] = bool(row.get('is_manual', False))

        data.append(worker_data)

    return data


def _ensure_next_workday_preloaded() -> None:
    next_day = get_next_workday().date()
    with lock:
        last_preload_date = global_worker_data.get('last_preload_date')
    if last_preload_date == next_day:
        return
    today = get_local_now().date()
    for modality in allowed_modalities:
        staged = staged_modality_data.get(modality, {})
        last_modified = staged.get('last_modified')
        if last_modified and last_modified.date() == today:
            return
    if not os.path.exists(MASTER_CSV_PATH):
        selection_logger.info(f"Lazy preload skipped: No master CSV at {MASTER_CSV_PATH}")
        return

    selection_logger.info(f"Lazy preload triggered from {MASTER_CSV_PATH}")
    result = preload_next_workday(MASTER_CSV_PATH, APP_CONFIG)
    if not result.get('success'):
        selection_logger.error(f"Lazy preload failed: {result.get('message')}")


def _get_staged_target_date() -> Optional[date]:
    for mod in allowed_modalities:
        target_date = staged_modality_data.get(mod, {}).get('target_date')
        if isinstance(target_date, date):
            return target_date
        if isinstance(target_date, str):
            try:
                return date.fromisoformat(target_date)
            except ValueError:
                continue
    return None


def resolve_modality_from_request() -> str:
    return normalize_modality(request.values.get('modality'))


def get_admin_password() -> str:
    """Get the admin password from config."""
    return APP_CONFIG.get("admin_password", "")


def get_access_password() -> str:
    """Get the basic access password from config."""
    return APP_CONFIG.get("access_password", "change_easy_pw")


def is_access_protection_enabled() -> bool:
    """Check if basic access protection is enabled."""
    return APP_CONFIG.get("access_protection_enabled")


def is_admin_protection_enabled() -> bool:
    """Check if admin access protection is enabled."""
    return APP_CONFIG.get("admin_access_protection_enabled")


def has_admin_access() -> bool:
    """Determine if the current session has admin access."""
    if not is_admin_protection_enabled():
        return True
    return session.get('admin_logged_in', False)


def has_basic_access() -> bool:
    """Determine if the current session has basic access (but not admin)."""
    return session.get('access_granted', False) and not session.get('admin_logged_in', False)


def is_authenticated() -> bool:
    """Check if user has any form of authentication (admin or basic)."""
    return session.get('admin_logged_in', False) or session.get('access_granted', False)


def access_required(f: Callable) -> Callable:
    """Decorator that requires basic access authentication for non-admin pages.

    Uses a long-lived session cookie so users don't need to re-login frequently.
    Admin login also grants basic access.
    """
    @wraps(f)
    def decorated(*args: Any, **kwargs: Any) -> Any:
        # Skip if access protection is disabled
        if not is_access_protection_enabled():
            return f(*args, **kwargs)
        # Admin login also grants access
        if session.get('admin_logged_in') or session.get('access_granted'):
            return f(*args, **kwargs)
        modality = resolve_modality_from_request()
        return redirect(url_for('routes.access_login', modality=modality))
    return decorated


def admin_required(f: Callable) -> Callable:
    @wraps(f)
    def decorated(*args: Any, **kwargs: Any) -> Any:
        if not has_admin_access():
            modality = resolve_modality_from_request()
            return redirect(url_for('routes.login', modality=modality))
        return f(*args, **kwargs)
    return decorated

# -----------------------------------------------------------
# Route Definitions
# -----------------------------------------------------------

@routes.context_processor
def inject_modality_settings() -> dict[str, Any]:
    return {
        'modalities': MODALITY_SETTINGS,
        'modality_order': allowed_modalities,
        'modality_labels': modality_labels,
        'skill_definitions': SKILL_TEMPLATES,
        'skill_order': SKILL_COLUMNS,
        'skill_labels': {s['name']: s['label'] for s in SKILL_TEMPLATES},
        # Auth state for templates
        'is_access_protection_enabled': is_access_protection_enabled(),
        'is_admin_protection_enabled': is_admin_protection_enabled(),
        'has_basic_access': has_basic_access(),
        'is_authenticated': is_authenticated(),
    }

@routes.route('/')
@access_required
def index() -> Any:
    modality = resolve_modality_from_request()
    d = modality_data[modality]

    modality_config = MODALITY_SETTINGS.get(modality, {})
    mod_valid_skills = set(modality_config.get('valid_skills', SKILL_COLUMNS))
    mod_hidden_skills = set(modality_config.get('hidden_skills', []))

    visible_skills = []
    for skill_name in SKILL_COLUMNS:
        if skill_name not in mod_valid_skills or skill_name in mod_hidden_skills:
            continue
        skill_config = SKILL_SETTINGS.get(skill_name, {})
        skill_valid_mods = skill_config.get('valid_modalities')
        skill_hidden_mods = set(skill_config.get('hidden_modalities', []))
        if skill_valid_mods is not None and modality not in skill_valid_mods:
            continue
        if modality in skill_hidden_mods:
            continue
        visible_skills.append(skill_name)

    return render_template(
        'index.html',
        info_texts=d.get('info_texts', []),
        modality=modality,
        visible_skills=visible_skills,
        is_admin=has_admin_access()
    )

@routes.route('/by-skill')
@access_required
def index_by_skill() -> Any:
    skill = request.args.get('skill', SKILL_COLUMNS[0] if SKILL_COLUMNS else 'Notfall')
    skill = normalize_skill(skill)

    skill_config = SKILL_SETTINGS.get(skill, {})
    skill_valid_mods = skill_config.get('valid_modalities')
    skill_hidden_mods = set(skill_config.get('hidden_modalities', []))

    visible_modalities = []
    for mod in allowed_modalities:
        if skill_valid_mods is not None and mod not in skill_valid_mods:
            continue
        if mod in skill_hidden_mods:
            continue
        mod_config = MODALITY_SETTINGS.get(mod, {})
        mod_valid_skills = mod_config.get('valid_skills')
        mod_hidden_skills = set(mod_config.get('hidden_skills', []))
        if mod_valid_skills is not None and skill not in mod_valid_skills:
            continue
        if skill in mod_hidden_skills:
            continue
        visible_modalities.append(mod)

    info_texts = []
    if allowed_modalities:
        first_modality = allowed_modalities[0]
        info_texts = modality_data[first_modality].get('info_texts', [])

    return render_template(
        'index_by_skill.html',
        skill=skill,
        visible_modalities=visible_modalities,
        info_texts=info_texts,
        is_admin=has_admin_access()
    )

@routes.route('/timetable')
@access_required
def timetable() -> Any:
    modality = request.args.get('modality', 'all')
    skill_filter = request.args.get('skill', 'all')
    
    # Combine data from all modalities or a specific one
    combined_data = []
    
    target_modalities = allowed_modalities if modality == 'all' else [modality]
    for mod in target_modalities:
        df = modality_data[mod]['working_hours_df']
        if df is not None:
            # Add modality info to each row for the frontend
            temp_df = df.copy()
            temp_df['_modality'] = mod
            combined_data.extend(_df_to_api_response(temp_df))
            
    # Skill slug/color maps for the frontend
    skill_slug_map = {s['name']: s['slug'] for s in SKILL_TEMPLATES}
    skill_color_map = {s['slug']: s['button_color'] for s in SKILL_TEMPLATES}
    modality_color_map = {mod: settings.get('nav_color', '#004892') for mod, settings in MODALITY_SETTINGS.items()}

    return render_template(
        'timetable.html',
        modality=modality,
        skill_filter=skill_filter,
        debug_data=json.dumps(combined_data),
        skill_columns=SKILL_COLUMNS,
        skill_slug_map=skill_slug_map,
        skill_color_map=skill_color_map,
        modality_color_map=modality_color_map,
        is_admin=has_admin_access()
    )

@routes.route('/skill-roster')
@admin_required
def skill_roster_page() -> Any:
    valid_skills_map = build_valid_skills_map()
    default_w_modifier = BALANCER_SETTINGS.get('default_w_modifier', 1.0)
    return render_template(
        'skill_roster.html',
        valid_skills_map=valid_skills_map,
        default_w_modifier=default_w_modifier,
        is_admin=True
    )

@routes.route('/api/admin/skill_roster', methods=['GET', 'POST'])
@admin_required
def skill_roster_api() -> Any:
    if request.method == 'POST':
        data = request.json
        roster = data.get('roster')
        if roster is not None:
            save_worker_skill_json(roster)
            return jsonify({'success': True})
        return jsonify({'error': 'No roster data'}), 400
    
    roster = load_worker_skill_json()
    worker_names = build_worker_name_mapping(roster)
    return jsonify({
        'success': True,
        'roster': roster,
        'worker_names': worker_names,
        'skills': SKILL_COLUMNS,
        'modalities': allowed_modalities
    })

@routes.route('/api/admin/skill_roster/import_new', methods=['POST'])
@admin_required
def import_new_skill_roster_api() -> Any:
    # Get current modality DFs
    current_dfs = {mod: modality_data[mod]['working_hours_df'] for mod in allowed_modalities}
    added_count, added_workers = auto_populate_skill_roster(current_dfs)
    return jsonify({
        'success': True,
        'added_count': added_count,
        'added_workers': added_workers
    })

@routes.route('/login', methods=['GET', 'POST'])
def login() -> Any:
    modality = resolve_modality_from_request()
    error = None
    passwordless = not is_admin_protection_enabled()

    if request.method == 'POST':
        if passwordless:
            # No password required - just proceed
            return redirect(url_for('routes.upload_file', modality=modality))
        pw = request.form.get('password', '')
        if pw == get_admin_password():
            session['admin_logged_in'] = True
            return redirect(url_for('routes.upload_file', modality=modality))
        else:
            error = "Falsches Passwort"

    return render_template("login.html", error=error, modality=modality, login_type='admin', passwordless=passwordless)

@routes.route('/logout')
def logout() -> Any:
    """Smart logout that handles both admin and basic auth levels.

    - If admin: clears admin session, redirects to login page
    - If basic access only: clears basic access, redirects to access-login
    - Hierarchy: admin logout takes precedence
    """
    modality = resolve_modality_from_request()

    if session.get('admin_logged_in'):
        # Admin logout - clear admin session, go to login page
        session.pop('admin_logged_in', None)
        return redirect(url_for('routes.login', modality=modality))

    if session.get('access_granted'):
        # Basic access logout - clear access, go to access-login page
        session.pop('access_granted', None)
        return redirect(url_for('routes.access_login', modality=modality))

    # Not logged in at all - just go to index
    return redirect(url_for('routes.index', modality=modality))


@routes.route('/access-login', methods=['GET', 'POST'])
def access_login() -> Any:
    """Basic access login for non-admin pages.

    Uses a permanent session cookie for long-lived access.
    """
    modality = resolve_modality_from_request()
    passwordless = not is_access_protection_enabled()

    # If already authenticated (either as admin or with basic access), redirect to index
    if session.get('admin_logged_in') or session.get('access_granted'):
        return redirect(url_for('routes.index', modality=modality))

    error = None
    if request.method == 'POST':
        if passwordless:
            # No password required - just proceed
            return redirect(url_for('routes.index', modality=modality))
        pw = request.form.get('password', '')
        if pw == get_access_password():
            session.permanent = True  # Use permanent session for long-lived cookie
            session['access_granted'] = True
            return redirect(url_for('routes.index', modality=modality))
        else:
            error = "Falsches Passwort"

    return render_template("login.html", error=error, modality=modality, login_type='access', passwordless=passwordless)


@routes.route('/access-logout')
def access_logout() -> Any:
    """Logout from basic access (keeps admin session if present)."""
    session.pop('access_granted', None)
    modality = resolve_modality_from_request()
    return redirect(url_for('routes.access_login', modality=modality))


@routes.route('/api/edit_info', methods=['POST'])
@admin_required
def edit_info() -> Any:
    """Update info texts for a specific modality"""
    try:
        data = request.get_json()
        modality = normalize_modality(data.get('modality', ''))
        info_text = data.get('info_text', '')

        if not modality or modality not in allowed_modalities:
            return jsonify({"success": False, "error": "Ungültige Modalität"}), 400

        # Split info_text by newlines and filter out empty lines
        info_texts = [line.strip() for line in info_text.split('\n') if line.strip()]

        # Update the modality data
        modality_data[modality]['info_texts'] = info_texts

        # Save the updated state and backup
        save_state()
        backup_dataframe(modality)

        selection_logger.info(f"Info texts updated for {modality} by admin")

        return jsonify({
            "success": True,
            "info_texts": info_texts,
            "message": "Info-Texte erfolgreich gespeichert"
        })
    except Exception as e:
        selection_logger.error(f"Error updating info texts: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@routes.route('/api/master-csv-status')
def master_csv_status() -> Any:
    if os.path.exists(MASTER_CSV_PATH):
        stat = os.stat(MASTER_CSV_PATH)
        modified = datetime.fromtimestamp(stat.st_mtime).strftime('%d.%m.%Y %H:%M')
        return jsonify({
            'exists': True,
            'filename': 'master_medweb.csv',
            'modified': modified,
            'size': stat.st_size
        })
    return jsonify({'exists': False})

@routes.route('/upload-master-csv', methods=['POST'])
@admin_required
def upload_master_csv() -> Any:
    if 'file' not in request.files:
        return jsonify({"error": "Keine Datei ausgewählt"}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "Keine Datei ausgewählt"}), 400

    if not file.filename.lower().endswith('.csv'):
        return jsonify({"error": "Bitte CSV-Datei hochladen"}), 400

    try:
        file.save(MASTER_CSV_PATH)
        selection_logger.info(f"Master CSV uploaded: {MASTER_CSV_PATH}")
        return jsonify({
            "success": True,
            "message": "Master-CSV erfolgreich hochgeladen"
        })
    except Exception as e:
        return jsonify({"error": f"Upload fehlgeschlagen: {str(e)}"}), 500


@routes.route('/preload-from-master', methods=['POST'])
@admin_required
def preload_from_master() -> Any:
    if not os.path.exists(MASTER_CSV_PATH):
        return jsonify({"error": "Keine Master-CSV vorhanden. Bitte zuerst hochladen."}), 400

    payload = request.get_json(silent=True) or {}
    target_date = payload.get('target_date') or request.form.get('target_date')
    if target_date:
        try:
            parsed_target_date = date.fromisoformat(target_date)
        except ValueError:
            return jsonify({"error": "Ungültiges Datum. Bitte YYYY-MM-DD nutzen."}), 400
        earliest_allowed = get_next_workday().date()
        if parsed_target_date < earliest_allowed:
            return jsonify({"error": f"Prep-Datum muss ab {earliest_allowed.isoformat()} liegen."}), 400
    result = preload_next_workday(MASTER_CSV_PATH, APP_CONFIG, target_date=target_date)

    if result['success']:
        state = StateManager.get_instance()
        scheduled_path = state.unified_schedule_paths['scheduled']
        if os.path.exists(scheduled_path):
            try:
                if load_unified_scheduled_into_staged(scheduled_path):
                    for modality in allowed_modalities:
                        backup_dataframe(modality, use_staged=True)
                    selection_logger.info("Staged data updated from unified scheduled file after preload")
            except Exception as e:
                selection_logger.error(f"Error loading staged data from unified schedule after preload: {e}")

        return jsonify(result)
    return jsonify(result), 400


@routes.route('/upload', methods=['GET'])
@admin_required
def upload_file() -> Any:
    """Admin dashboard page for CSV management and statistics."""
    modality = resolve_modality_from_request()
    d = modality_data[modality]

    all_worker_names = set()
    combined_skill_counts = {skill: {} for skill in SKILL_COLUMNS}

    for mod_key in allowed_modalities:
        mod_d = modality_data[mod_key]
        for skill in SKILL_COLUMNS:
            for worker, count in mod_d['skill_counts'].get(skill, {}).items():
                all_worker_names.add(worker)
                if worker not in combined_skill_counts[skill]:
                    combined_skill_counts[skill][worker] = 0
                combined_skill_counts[skill][worker] += count

    sum_counts = {}
    global_counts = {}
    global_weighted_counts = {}
    for worker in all_worker_names:
        total = sum(combined_skill_counts[skill].get(worker, 0) for skill in SKILL_COLUMNS)
        sum_counts[worker] = total

        canonical = get_canonical_worker_id(worker)
        global_counts[worker] = get_global_assignments(canonical)
        global_weighted_counts[worker] = get_global_weighted_count(canonical)

    combined_workers = sorted(all_worker_names)
    modality_stats = {}
    for worker in combined_workers:
        modality_stats[worker] = {
            skill: combined_skill_counts[skill].get(worker, 0)
            for skill in SKILL_COLUMNS
        }
        modality_stats[worker]['total'] = sum_counts.get(worker, 0)

    debug_info = (
        d['working_hours_df'].to_html(index=True)
        if d['working_hours_df'] is not None else "Keine Daten verfügbar"
    )

    checks = run_operational_checks('admin_view', force=True)

    return render_template(
        'upload.html',
        debug_info=debug_info,
        modality=modality,
        skill_counts=combined_skill_counts,
        sum_counts=sum_counts,
        global_counts=global_counts,
        global_weighted_counts=global_weighted_counts,
        combined_workers=combined_workers,
        modality_stats=modality_stats,
        operational_checks=checks,
        scheduler_config=APP_CONFIG.get('scheduler', {}),
        is_admin=True
    )

def _check_config_file() -> dict[str, str]:
    """Check if APP_CONFIG is loaded."""
    if APP_CONFIG:
        return {'status': 'OK', 'detail': 'APP_CONFIG is loaded and available'}
    return {'status': 'ERROR', 'detail': 'APP_CONFIG is not loaded or empty'}


def _check_scheduler() -> dict[str, str]:
    """Check scheduler configuration."""
    scheduler_conf = APP_CONFIG.get('scheduler', {})
    reset_time = scheduler_conf.get('daily_reset_time', '07:30')
    return {'status': 'OK', 'detail': f'Resets at {reset_time}, lazy preload on demand'}


def _check_admin_password() -> dict[str, str]:
    """Check admin password configuration."""
    admin_pw = get_admin_password()
    if not admin_pw:
        return {'status': 'WARNING', 'detail': 'Admin password is not set in config.yaml'}
    if admin_pw == 'change_pw_for_live':
        return {'status': 'WARNING', 'detail': 'Admin password is still set to default value - change for production!'}
    return {'status': 'OK', 'detail': 'Admin password is configured'}


def _check_upload_folder() -> dict[str, str]:
    """Check upload folder exists and is writable."""
    upload_folder = 'uploads'
    if not os.path.exists(upload_folder):
        return {'status': 'WARNING', 'detail': f'Upload folder "{upload_folder}" does not exist (will be created on upload)'}
    if not os.access(upload_folder, os.W_OK):
        return {'status': 'ERROR', 'detail': f'Upload folder "{upload_folder}" is not writable'}
    has_master_csv = os.path.exists(os.path.join(upload_folder, 'master_medweb.csv'))
    csv_status = "Master CSV present" if has_master_csv else "No Master CSV"
    return {'status': 'OK', 'detail': f'Upload folder "{upload_folder}" is writable ({csv_status})'}


def _check_modalities() -> dict[str, str]:
    """Check modality configuration."""
    modality_count = len(allowed_modalities)
    if modality_count == 0:
        return {'status': 'ERROR', 'detail': 'No modalities configured in config.yaml'}
    return {'status': 'OK', 'detail': f'{modality_count} modalities configured: {", ".join(allowed_modalities)}'}


def _check_skills() -> dict[str, str]:
    """Check skill configuration."""
    skill_count = len(SKILL_COLUMNS)
    if skill_count == 0:
        return {'status': 'ERROR', 'detail': 'No skills configured in config.yaml'}
    return {'status': 'OK', 'detail': f'{skill_count} skills configured: {", ".join(SKILL_COLUMNS)}'}


def _check_worker_data() -> dict[str, str]:
    """Check worker data is loaded."""
    total_workers = 0
    for mod in allowed_modalities:
        d = modality_data.get(mod, {})
        if d.get('working_hours_df') is not None:
            total_workers += len(d['working_hours_df']['PPL'].unique())

    if total_workers == 0:
        return {'status': 'WARNING', 'detail': 'No worker data loaded - upload Master CSV and use Load Today'}
    return {'status': 'OK', 'detail': f'{total_workers} workers loaded across all modalities'}


def run_operational_checks(context: str = 'unknown', force: bool = False) -> dict[str, Any]:
    """Run all operational checks and return results."""
    checks = [
        ('Config File', _check_config_file),
        ('Scheduler', _check_scheduler),
        ('Admin Password', _check_admin_password),
        ('Upload Folder', _check_upload_folder),
        ('Modalities', _check_modalities),
        ('Skills', _check_skills),
        ('Worker Data', _check_worker_data),
    ]

    results = []
    for name, check_fn in checks:
        try:
            result = check_fn()
            results.append({'name': name, **result})
        except Exception as e:
            results.append({'name': name, 'status': 'ERROR', 'detail': f'Failed to check {name.lower()}: {str(e)}'})

    return {
        'results': results,
        'context': context,
        'timestamp': get_local_now().isoformat()
    }

@routes.route('/load-today-from-master', methods=['POST'])
@admin_required
def load_today_from_master() -> Any:
    if not os.path.exists(MASTER_CSV_PATH):
        return jsonify({"error": "Keine Master-CSV vorhanden. Bitte zuerst CSV hochladen."}), 400

    try:
        target_date = get_local_now()

        # Debug: Check CSV content before parsing
        try:
            vendor_mapping = APP_CONFIG.get('medweb_mapping', {})
            cols = vendor_mapping.get('columns', {
                'date': 'Datum',
                'activity': 'Beschreibung der Aktivität'
            })
            date_col = cols.get('date', 'Datum')
            activity_col = cols.get('activity', 'Beschreibung der Aktivität')

            try:
                debug_df = pd.read_csv(MASTER_CSV_PATH, sep=',', encoding='utf-8')
            except UnicodeDecodeError:
                debug_df = pd.read_csv(MASTER_CSV_PATH, sep=',', encoding='latin1')
            if date_col not in debug_df.columns:
                try:
                    debug_df = pd.read_csv(MASTER_CSV_PATH, sep=';', encoding='utf-8')
                except UnicodeDecodeError:
                    debug_df = pd.read_csv(MASTER_CSV_PATH, sep=';', encoding='latin1')

            available_dates = debug_df[date_col].unique().tolist() if date_col in debug_df.columns else []
            available_activities = debug_df[activity_col].unique().tolist() if activity_col in debug_df.columns else []
        except Exception as e:
            return jsonify({"error": f"CSV-Lesefehler: {str(e)}"}), 400

        # Acquire lock BEFORE parsing CSV to prevent race conditions
        # when multiple requests overlap - data parsing must be atomic
        with lock:
            modality_dfs = build_working_hours_from_medweb(
                MASTER_CSV_PATH,
                target_date,
                APP_CONFIG
            )

            # ALWAYS reset global state and ALL modalities first to prevent stale data
            # This handles both empty returns and partial modality returns
            global_worker_data['weighted_counts'] = {}

            for modality in allowed_modalities:
                d = modality_data[modality]
                d['skill_counts'] = {skill: {} for skill in SKILL_COLUMNS}
                d['working_hours_df'] = None
                d['info_texts'] = []
                global_worker_data['assignments_per_mod'][modality] = {}

            if not modality_dfs:
                # No staff entries found - this is OK, not all shifts have staff (balancer handles this)
                mapping_rules = APP_CONFIG.get('medweb_mapping', {}).get('rules', [])
                rule_matches = [r.get('match', '') for r in mapping_rules[:10]]
                matched_activities = []
                for activity in available_activities:
                    for rule in mapping_rules:
                        if rule.get('match', '').lower() in str(activity).lower():
                            matched_activities.append(activity)
                            break

                selection_logger.info(f"No staff entries found for {target_date.strftime('%d.%m.%Y')} - this is expected for some shifts")

                # Persist cleared state
                save_state()

                return jsonify({
                    "success": True,
                    "message": f"Keine Mitarbeiter für {target_date.strftime('%d.%m.%Y')} gefunden - Schichten können leer sein",
                    "modalities_loaded": [],
                    "total_workers": 0,
                    "workers_added_to_roster": 0,
                    "info": {
                        "target_date": target_date.strftime('%d.%m.%Y'),
                        "dates_in_csv": available_dates[:10],
                        "activities_in_csv": available_activities[:10],
                        "mapping_rules": rule_matches,
                        "matched_activities": matched_activities[:10],
                    }
                })

            # Now populate modalities that have data (others remain cleared)
            for modality, df in modality_dfs.items():
                d = modality_data[modality]
                d['working_hours_df'] = df

                if df is None or df.empty:
                    continue

                for worker in df['PPL'].unique():
                    for skill in SKILL_COLUMNS:
                        if skill not in d['skill_counts']:
                            d['skill_counts'][skill] = {}
                        d['skill_counts'][skill][worker] = 0

                d['info_texts'] = []

        # Persist state OUTSIDE the lock to prevent blocking I/O
        save_state()

        workers_added = 0
        if SKILL_ROSTER_AUTO_IMPORT:
            workers_added, _ = auto_populate_skill_roster(modality_dfs)

        return jsonify({
            "success": True,
            "message": f"Heute ({target_date.strftime('%d.%m.%Y')}) aus Master-CSV geladen",
            "modalities_loaded": list(modality_dfs.keys()),
            "total_workers": sum(len(df) for df in modality_dfs.values()),
            "workers_added_to_roster": workers_added
        })

    except Exception as e:
        return jsonify({"error": f"Fehler: {str(e)}"}), 500

def _render_prep_page(initial_tab: str) -> Any:
    staged_target_date = _get_staged_target_date()
    if initial_tab == 'tomorrow' and staged_target_date is None:
        _ensure_next_workday_preloaded()
    prep_min_date = get_next_workday().date()
    next_day = staged_target_date or prep_min_date
    next_day_dt = next_day if isinstance(next_day, datetime) else datetime.combine(next_day, datetime.min.time())
    target_date_str = next_day_dt.strftime('%Y-%m-%d')
    target_date_german = next_day_dt.strftime('%d.%m.%Y')
    target_weekday_name = get_weekday_name_german(next_day_dt.date())

    roster = load_worker_skill_json()
    if roster is None:
        roster = {}
    worker_list = list(roster.keys())
    worker_names = build_worker_name_mapping(roster)

    medweb_rules = APP_CONFIG.get('medweb_mapping', {}).get('rules', [])
    task_roles = []
    for rule in medweb_rules:
        rule_type = rule.get('type', 'shift')
        hours_counting_config = APP_CONFIG.get('balancer', {}).get('hours_counting', {})
        if 'counts_for_hours' in rule:
            counts_for_hours = rule['counts_for_hours']
        elif rule_type == 'gap':
            counts_for_hours = hours_counting_config.get('gap_default', False)
        else:
            counts_for_hours = hours_counting_config.get('shift_default', True)

        # Extract modalities from skill_overrides using shared helper
        skill_overrides = rule.get('skill_overrides', {})
        modalities_list = extract_modalities_from_skill_overrides(skill_overrides)

        task_role = {
            'name': rule.get('label', rule.get('match', '')),
            'type': rule_type,
            'modalities': modalities_list,
            'times': rule.get('times', {}),
            'gaps': rule.get('gaps', {}),
            'skill_overrides': skill_overrides,
            'modifier': rule.get('modifier', 1.0),
            'counts_for_hours': counts_for_hours,
        }
        task_roles.append(task_role)

    worker_skills = load_worker_skill_json()

    # Quick break config with defaults
    quick_break_config = APP_CONFIG.get('balancer', {}).get('quick_break', {})
    quick_break = {
        'duration_minutes': quick_break_config.get('duration_minutes', 30),
        'gap_type': quick_break_config.get('gap_type', 'Break')
    }

    return render_template(
        'prep_next_day.html',
        target_date=target_date_str,
        target_date_german=target_date_german,
        target_weekday_name=target_weekday_name,
        prep_min_date=prep_min_date.strftime('%Y-%m-%d'),
        is_next_day=True,
        initial_tab=initial_tab,
        skills=SKILL_COLUMNS,
        skill_settings=SKILL_SETTINGS,
        modalities=list(MODALITY_SETTINGS.keys()),
        modality_settings=MODALITY_SETTINGS,
        worker_list=worker_list,
        worker_names=worker_names,
        worker_skills=worker_skills,
        task_roles=task_roles,
        skill_value_colors=APP_CONFIG.get('skill_value_colors', {}),
        ui_colors=APP_CONFIG.get('ui_colors', {}),
        quick_break=quick_break,
        is_admin=True
    )


@routes.route('/prep-today')
@admin_required
def prep_today() -> Any:
    return _render_prep_page('today')


@routes.route('/prep-tomorrow')
@admin_required
def prep_tomorrow() -> Any:
    return _render_prep_page('tomorrow')

@routes.route('/api/prep-next-day/data', methods=['GET'])
@admin_required
def get_prep_data() -> Any:
    result = {}
    staged_target_date = _get_staged_target_date()
    if staged_target_date is None:
        _ensure_next_workday_preloaded()

    # Acquire lock to prevent race conditions when reading/writing staged data
    with lock:
        for modality in allowed_modalities:
            if staged_modality_data[modality]['working_hours_df'] is None:
                if not load_staged_dataframe(modality):
                    if modality_data[modality]['working_hours_df'] is not None:
                        staged_modality_data[modality]['working_hours_df'] = modality_data[modality]['working_hours_df'].copy()
                        staged_modality_data[modality]['info_texts'] = modality_data[modality]['info_texts'].copy()
                        backup_dataframe(modality, use_staged=True)

            df = staged_modality_data[modality].get('working_hours_df')
            result[modality] = _df_to_api_response(df)

        last_prepped_at = staged_modality_data[allowed_modalities[0]].get('last_prepped_at')
        target_date = staged_modality_data[allowed_modalities[0]].get('target_date')

    target_date_obj = None
    if isinstance(target_date, date):
        target_date_obj = target_date
    elif isinstance(target_date, str):
        try:
            target_date_obj = date.fromisoformat(target_date)
        except ValueError:
            target_date_obj = None
    if target_date_obj is None:
        target_date_obj = get_next_workday().date()

    return jsonify({
        'modalities': result,
        'last_prepped_at': last_prepped_at,
        'target_date': target_date_obj.isoformat(),
        'target_weekday_name': get_weekday_name_german(target_date_obj),
    })

@routes.route('/api/prep-next-day/update-row', methods=['POST'])
@admin_required
def update_prep_row() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    updates = data.get('updates', {})

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, result = _update_schedule_row(modality, row_index, updates, use_staged=True)

    if success:
        # result is {'reindexed': bool} on success
        return jsonify({'success': True, 'schedule_reindexed': result.get('reindexed', False)})
    return jsonify({'error': result}), 400

@routes.route('/api/prep-next-day/add-worker', methods=['POST'])
@admin_required
def add_prep_worker() -> Any:
    data = request.json
    modality = data.get('modality')
    worker_data = data.get('worker_data', {})

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, result, error = _add_worker_to_schedule(modality, worker_data, use_staged=True)

    if success:
        # result is {'row_index': int, 'reindexed': bool} on success
        return jsonify({
            'success': True,
            'row_index': result.get('row_index'),
            'schedule_reindexed': result.get('reindexed', False)
        })
    return jsonify({'error': error}), 400

@routes.route('/api/prep-next-day/delete-worker', methods=['POST'])
@admin_required
def delete_prep_worker() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    verify_ppl = data.get('verify_ppl')

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, worker_name, error = _delete_worker_from_schedule(modality, row_index, use_staged=True, verify_ppl=verify_ppl)

    if success:
        return jsonify({'success': True})
    return jsonify({'error': error}), 400

@routes.route('/api/live-schedule/data', methods=['GET'])
@admin_required
def get_live_data() -> Any:
    result = {}
    for modality in allowed_modalities:
        df = modality_data[modality].get('working_hours_df')
        result[modality] = _df_to_api_response(df)
    return jsonify(result)

@routes.route('/api/live-schedule/update-row', methods=['POST'])
@admin_required
def update_live_row() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    updates = data.get('updates', {})

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, result = _update_schedule_row(modality, row_index, updates, use_staged=False)

    if success:
        selection_logger.info(f"Live schedule updated for {modality}, row {row_index} (no counter reset)")
        # result is {'reindexed': bool} on success
        return jsonify({'success': True, 'schedule_reindexed': result.get('reindexed', False)})
    return jsonify({'error': result}), 400

@routes.route('/api/live-schedule/add-worker', methods=['POST'])
@admin_required
def add_live_worker() -> Any:
    data = request.json
    modality = data.get('modality')
    worker_data = data.get('worker_data', {})

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    ppl_name = worker_data.get('PPL', 'Neuer Worker (NW)')
    success, result, error = _add_worker_to_schedule(modality, worker_data, use_staged=False)

    if success:
        d = modality_data[modality]
        for skill in SKILL_COLUMNS:
            if skill not in d['skill_counts']:
                d['skill_counts'][skill] = {}
            if ppl_name not in d['skill_counts'][skill]:
                d['skill_counts'][skill][ppl_name] = 0

        selection_logger.info(f"Worker {ppl_name} added to LIVE {modality} schedule (no counter reset)")
        # result is {'row_index': int, 'reindexed': bool} on success
        return jsonify({
            'success': True,
            'row_index': result.get('row_index'),
            'schedule_reindexed': result.get('reindexed', False)
        })

    return jsonify({'error': error}), 400

@routes.route('/api/live-schedule/delete-worker', methods=['POST'])
@admin_required
def delete_live_worker() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    verify_ppl = data.get('verify_ppl')

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, worker_name, error = _delete_worker_from_schedule(modality, row_index, use_staged=False, verify_ppl=verify_ppl)

    if success:
        selection_logger.info(f"Worker {worker_name} deleted from LIVE {modality} schedule (no counter reset)")
        return jsonify({'success': True})

    return jsonify({'error': error}), 400

@routes.route('/api/live-schedule/add-gap', methods=['POST'])
@admin_required
def add_live_gap() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_type = data.get('gap_type', 'custom')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_counts_for_hours = data.get('gap_counts_for_hours')

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, action, error = _add_gap_to_schedule(
        modality,
        row_index,
        gap_type,
        gap_start,
        gap_end,
        use_staged=False,
        gap_counts_for_hours=gap_counts_for_hours
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400

@routes.route('/api/prep-next-day/add-gap', methods=['POST'])
@admin_required
def add_staged_gap() -> Any:
    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_type = data.get('gap_type', 'custom')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_counts_for_hours = data.get('gap_counts_for_hours')

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    success, action, error = _add_gap_to_schedule(
        modality,
        row_index,
        gap_type,
        gap_start,
        gap_end,
        use_staged=True,
        gap_counts_for_hours=gap_counts_for_hours
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400


@routes.route('/api/live-schedule/remove-gap', methods=['POST'])
@admin_required
def remove_live_gap() -> Any:
    """Remove a gap from a live schedule shift."""
    from data_manager.schedule_crud import _remove_gap_from_schedule

    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_index = data.get('gap_index')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_activity = data.get('gap_activity')

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    if gap_index is None and (gap_start is None or gap_end is None):
        return jsonify({'error': 'gap_start and gap_end are required when gap_index is missing'}), 400

    gap_match = {
        'start': gap_start,
        'end': gap_end,
        'activity': gap_activity
    }
    success, action, error = _remove_gap_from_schedule(
        modality,
        row_index,
        gap_index,
        use_staged=False,
        gap_match=gap_match if gap_index is None else None
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400


@routes.route('/api/prep-next-day/remove-gap', methods=['POST'])
@admin_required
def remove_staged_gap() -> Any:
    """Remove a gap from a staged schedule shift."""
    from data_manager.schedule_crud import _remove_gap_from_schedule

    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_index = data.get('gap_index')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_activity = data.get('gap_activity')

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    if gap_index is None and (gap_start is None or gap_end is None):
        return jsonify({'error': 'gap_start and gap_end are required when gap_index is missing'}), 400

    gap_match = {
        'start': gap_start,
        'end': gap_end,
        'activity': gap_activity
    }
    success, action, error = _remove_gap_from_schedule(
        modality,
        row_index,
        gap_index,
        use_staged=True,
        gap_match=gap_match if gap_index is None else None
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400


@routes.route('/api/live-schedule/update-gap', methods=['POST'])
@admin_required
def update_live_gap() -> Any:
    """Update a gap in a live schedule shift."""
    from data_manager.schedule_crud import _update_gap_in_schedule

    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_index = data.get('gap_index')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_activity = data.get('gap_activity')
    new_start = data.get('new_start')
    new_end = data.get('new_end')
    new_activity = data.get('new_activity')
    new_counts_for_hours = data.get('new_counts_for_hours')

    if modality not in modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    if gap_index is None and (gap_start is None or gap_end is None):
        return jsonify({'error': 'gap_start and gap_end are required when gap_index is missing'}), 400

    success, action, error = _update_gap_in_schedule(
        modality,
        row_index,
        gap_index,
        new_start,
        new_end,
        new_activity,
        use_staged=False,
        new_counts_for_hours=new_counts_for_hours,
        gap_match={'start': gap_start, 'end': gap_end, 'activity': gap_activity}
        if gap_index is None else None
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400


@routes.route('/api/prep-next-day/update-gap', methods=['POST'])
@admin_required
def update_staged_gap() -> Any:
    """Update a gap in a staged schedule shift."""
    from data_manager.schedule_crud import _update_gap_in_schedule

    data = request.json
    modality = data.get('modality')
    row_index = data.get('row_index')
    gap_index = data.get('gap_index')
    gap_start = data.get('gap_start')
    gap_end = data.get('gap_end')
    gap_activity = data.get('gap_activity')
    new_start = data.get('new_start')
    new_end = data.get('new_end')
    new_activity = data.get('new_activity')
    new_counts_for_hours = data.get('new_counts_for_hours')

    if modality not in staged_modality_data:
        return jsonify({'error': 'Invalid modality'}), 400

    if gap_index is None and (gap_start is None or gap_end is None):
        return jsonify({'error': 'gap_start and gap_end are required when gap_index is missing'}), 400

    success, action, error = _update_gap_in_schedule(
        modality,
        row_index,
        gap_index,
        new_start,
        new_end,
        new_activity,
        use_staged=True,
        new_counts_for_hours=new_counts_for_hours,
        gap_match={'start': gap_start, 'end': gap_end, 'activity': gap_activity}
        if gap_index is None else None
    )

    if success:
        return jsonify({'success': True, 'action': action})
    return jsonify({'error': error}), 400


def _assign_worker(modality: str, role: str, allow_overflow: bool = True) -> Any:
    try:
        now = get_local_now()

        # Check if this skill×modality combo has overflow disabled
        canonical_skill = normalize_skill(role)
        if allow_overflow and is_no_overflow(canonical_skill, modality):
            allow_overflow = False
            selection_logger.info(
                "No-overflow config active for %s_%s, forcing strict mode",
                canonical_skill,
                modality,
            )

        selection_logger.info(
            "Assignment request: modality=%s, role=%s, strict=%s, time=%s",
            modality,
            role,
            not allow_overflow,
            now.strftime('%H:%M:%S'),
        )

        # Store response data to return after releasing lock
        response_data = None
        state_modified = False

        with lock:
            result = get_next_available_worker(
                now,
                role=role,
                modality=modality,
                allow_overflow=allow_overflow,
            )
            if result is not None:
                candidate, used_column, source_modality = result
                actual_modality = source_modality or modality
                d = modality_data[actual_modality]

                candidate = candidate.to_dict() if hasattr(candidate, "to_dict") else dict(candidate)
                if "PPL" not in candidate:
                    raise ValueError("Candidate row is missing the 'PPL' field")
                person = candidate['PPL']

                actual_skill = candidate.get('__skill_source')
                if not actual_skill and isinstance(used_column, str):
                    actual_skill = used_column
                if not actual_skill:
                    actual_skill = role

                selection_logger.info(
                    "Selected worker: %s using column %s (modality %s)",
                    person,
                    actual_skill,
                    actual_modality,
                )

                if actual_skill in SKILL_COLUMNS:
                    if actual_skill not in d['skill_counts']:
                        d['skill_counts'][actual_skill] = {}
                    if person not in d['skill_counts'][actual_skill]:
                        d['skill_counts'][actual_skill][person] = 0
                    d['skill_counts'][actual_skill][person] += 1

                # Check if this is a weighted ('w') assignment - only 'w' uses modifier
                is_weighted = candidate.get('__is_weighted', False)
                canonical_id = update_global_assignment(person, actual_skill, actual_modality, is_weighted)
                state_modified = True

                # Record skill-modality usage for analytics
                usage_logger.record_skill_modality_usage(actual_skill, actual_modality)

                # Check if it's time for scheduled export (7:30 AM)
                usage_logger.check_and_export_at_scheduled_time()

                response_data = {
                    "selected_person": person,
                    "canonical_id": canonical_id,
                    "source_modality": actual_modality,
                    "skill_used": actual_skill,
                    "is_weighted": is_weighted
                }
            else:
                selection_logger.warning("No available worker found")
                return jsonify({"error": "No available worker found"}), 404

        # Persist state OUTSIDE the lock to prevent blocking I/O
        if state_modified:
            save_state()

        return jsonify(response_data)

    except Exception as e:
        selection_logger.error(f"Error selecting worker: {str(e)}", exc_info=True)
        return jsonify({"error": str(e)}), 500

@routes.route('/api/<modality>/<role>', methods=['GET'])
@access_required
def assign_worker_api(modality: str, role: str) -> Any:
    modality = normalize_modality(modality)
    if modality not in modality_data:
        return jsonify({"error": "Invalid modality"}), 400
    return _assign_worker(modality, role)

@routes.route('/api/<modality>/<role>/strict', methods=['GET'])
@access_required
def assign_worker_strict_api(modality: str, role: str) -> Any:
    modality = normalize_modality(modality)
    if modality not in modality_data:
        return jsonify({"error": "Invalid modality"}), 400
    return _assign_worker(modality, role, allow_overflow=False)

# Usage Statistics API Endpoints

@routes.route('/api/usage-stats/current', methods=['GET'])
@admin_required
def get_current_usage_stats() -> Any:
    """Get current daily usage statistics for skill-modality combinations."""
    stats = usage_logger.get_current_usage_stats()

    # Convert to list format for easier consumption
    stats_list = [
        {
            'skill': skill,
            'modality': modality,
            'count': count
        }
        for (skill, modality), count in sorted(stats.items())
    ]

    return jsonify({
        'date': get_local_now().strftime('%Y-%m-%d'),
        'total_combinations': len(stats_list),
        'total_usages': sum(s['count'] for s in stats_list),
        'stats': stats_list
    })

@routes.route('/api/usage-stats/export', methods=['POST'])
@admin_required
def export_usage_stats() -> Any:
    """Manually trigger export of current usage statistics to CSV (wide format)."""
    try:
        csv_path = usage_logger.export_current_usage()
        if csv_path:
            return jsonify({
                'success': True,
                'message': 'Usage statistics exported successfully (appended to CSV)',
                'file_path': str(csv_path),
                'date': datetime.now().strftime('%Y-%m-%d'),
                'note': 'Data appended as new row in wide format CSV'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'No usage data to export'
            })
    except Exception as e:
        selection_logger.error(f"Error exporting usage stats: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@routes.route('/api/usage-stats/reset', methods=['POST'])
@admin_required
def reset_usage_stats() -> Any:
    """Reset current usage statistics (use with caution)."""
    try:
        usage_logger.reset_daily_usage()
        return jsonify({
            'success': True,
            'message': 'Usage statistics reset successfully'
        })
    except Exception as e:
        selection_logger.error(f"Error resetting usage stats: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@routes.route('/api/usage-stats/file', methods=['GET'])
@admin_required
def get_usage_stats_file_info() -> Any:
    """Get information about the usage statistics CSV file."""
    try:
        csv_path = usage_logger.USAGE_STATS_FILE

        if not csv_path.exists():
            return jsonify({
                'success': True,
                'exists': False,
                'message': 'No usage statistics file exists yet'
            })

        # Read dates from the CSV
        import csv
        dates = []
        with open(csv_path, 'r', newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if 'date' in row:
                    dates.append(row['date'])

        return jsonify({
            'success': True,
            'exists': True,
            'filename': csv_path.name,
            'path': str(csv_path),
            'size_bytes': csv_path.stat().st_size,
            'total_days': len(dates),
            'dates': dates,
            'date_range': {
                'first': dates[0] if dates else None,
                'last': dates[-1] if dates else None
            }
        })
    except Exception as e:
        selection_logger.error(f"Error getting usage stats file info: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# =============================================================================
# WORKER LOAD MONITOR
# =============================================================================

@routes.route('/worker-load')
@admin_required
def worker_load_monitor() -> Any:
    """Worker load monitoring page with simple/advanced views."""
    load_monitor_config = APP_CONFIG.get('worker_load_monitor', {})

    return render_template(
        'worker_load_monitor.html',
        skills=SKILL_COLUMNS,
        skill_settings=SKILL_SETTINGS,
        modalities=list(MODALITY_SETTINGS.keys()),
        modality_settings=MODALITY_SETTINGS,
        load_monitor_config=load_monitor_config,
        ui_colors=APP_CONFIG.get('ui_colors', {}),
        is_admin=True
    )


@routes.route('/api/worker-load/data', methods=['GET'])
@admin_required
def get_worker_load_data() -> Any:
    """API endpoint returning all worker load data for monitoring."""
    # Collect all unique workers across all modalities
    all_workers = {}  # canonical_id -> {name, shift_info, modality_data}

    for modality in allowed_modalities:
        d = modality_data[modality]
        df = d.get('working_hours_df')
        if df is None or df.empty:
            continue

        for idx, row in df.iterrows():
            worker_name = row['PPL']
            canonical_id = get_canonical_worker_id(worker_name)

            if canonical_id not in all_workers:
                all_workers[canonical_id] = {
                    'name': worker_name,
                    'canonical_id': canonical_id,
                    'modalities': {},
                    'skills': {},
                    'global_weight': 0.0,
                    'global_assignments': {}
                }

            # Store modality-specific data
            mod_data = {
                'start_time': row['start_time'].strftime('%H:%M') if pd.notnull(row.get('start_time')) else '',
                'end_time': row['end_time'].strftime('%H:%M') if pd.notnull(row.get('end_time')) else '',
                'modifier': float(row.get('Modifier', 1.0)) if pd.notnull(row.get('Modifier')) else 1.0,
                'skills': {},
                'skill_counts': {},
                # Compute per-modality weight from assignments_per_mod using skill×modality weights
                'weighted_count': get_modality_weighted_count(canonical_id, modality)
            }

            # Collect skill values and counts for this modality
            for skill in SKILL_COLUMNS:
                skill_val = row.get(skill, None)
                mod_data['skills'][skill] = skill_value_to_display(skill_val)
                # Get skill count for this worker in this modality
                mod_data['skill_counts'][skill] = d['skill_counts'].get(skill, {}).get(worker_name, 0)

            all_workers[canonical_id]['modalities'][modality] = mod_data

    # Add global weighted counts and assignments
    for canonical_id, worker_data in all_workers.items():
        worker_data['global_weight'] = get_global_weighted_count(canonical_id)
        worker_data['global_assignments'] = get_global_assignments(canonical_id)

        # Aggregate per-skill totals across modalities
        for skill in SKILL_COLUMNS:
            total_count = 0
            for mod_key, mod_data in worker_data['modalities'].items():
                total_count += mod_data['skill_counts'].get(skill, 0)
            worker_data['skills'][skill] = total_count

    # Calculate per-modality weight totals
    modality_weights = {}
    for modality in allowed_modalities:
        modality_weights[modality] = {}
        for canonical_id, worker_data in all_workers.items():
            if modality in worker_data['modalities']:
                modality_weights[modality][canonical_id] = worker_data['modalities'][modality]['weighted_count']

    # Calculate per-skill weight totals (using global weighted assignment data)
    skill_weights = {skill: {} for skill in SKILL_COLUMNS}
    for mod in allowed_modalities:
        d = modality_data[mod]
        for skill in SKILL_COLUMNS:
            skill_counts = d['skill_counts'].get(skill, {})
            for worker_name, count in skill_counts.items():
                canonical_id = get_canonical_worker_id(worker_name)
                if canonical_id not in skill_weights[skill]:
                    skill_weights[skill][canonical_id] = 0
                skill_weights[skill][canonical_id] += count

    # Get max weight for relative color coding
    max_weight = max((w['global_weight'] for w in all_workers.values()), default=0.0)

    return jsonify({
        'success': True,
        'workers': list(all_workers.values()),
        'modality_weights': modality_weights,
        'skill_weights': skill_weights,
        'max_weight': max_weight,
        'skills': SKILL_COLUMNS,
        'modalities': allowed_modalities,
        'config': APP_CONFIG.get('worker_load_monitor', {})
    })
