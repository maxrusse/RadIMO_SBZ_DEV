{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update test_data dates to the next full workweek\\n",
        "\\n",
        "This cell replaces placeholder dates (xx/yy/zz) or base dates (e.g. 01.01.1970) in the CSVs with the next Monday plus four days (Mon-Fri), then writes `*_today.csv` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import csv\n",
        "import datetime as dt\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "DATE_TOKEN_RE = re.compile(r\\"\\b(\\d{2}\\.\\d{2}\\.\\d{4}|xx\\.xx\\.xxxx|yy\\.yy\\.yyyy|zz\\.zz\\.zzzz)\\b\\")\n",
        "PLACEHOLDER_OFFSETS = {\"xx.xx.xxxx\": 0, \"yy.yy.yyyy\": 1, \"zz.zz.zzzz\": 2}\n",
        "\n",
        "def parse_date(value: str) -> dt.date:\n",
        "    return dt.datetime.strptime(value, \\\"%d.%m.%Y\\\").date()\n",
        "\n",
        "def extract_dates(rows: list[dict[str, str]], fieldnames: list[str]) -> list[str]:\n",
        "    if \"Datum\" in fieldnames:\n",
        "        values = [row[\"Datum\"].strip() for row in rows if row.get(\"Datum\")]\n",
        "    else:\n",
        "        values = []\n",
        "    if not values:\n",
        "        for row in rows:\n",
        "            for value in row.values():\n",
        "                if value:\n",
        "                    values.extend(DATE_TOKEN_RE.findall(value))\n",
        "    return [value for value in values if value not in PLACEHOLDER_OFFSETS]\n",
        "\n",
        "def next_weekday(start: dt.date, weekday: int) -> dt.date:\n",
        "    days_ahead = (weekday - start.weekday()) % 7\n",
        "    if days_ahead == 0:\n",
        "        return start\n",
        "    return start + dt.timedelta(days=days_ahead)\n",
        "\n",
        "def get_start_date(anchor: dt.date | None = None) -> dt.date:\n",
        "    base = anchor or dt.date.today()\n",
        "    return next_weekday(base, 0)  # 0 = Monday\n",
        "\n",
        "def build_date_mapping(unique_dates: list[str], days: int = 5) -> tuple[dict[str, str], dt.date]:\n",
        "    if len(unique_dates) > days:\n",
        "        raise ValueError(f\"Found {len(unique_dates)} unique dates but only {days} days were provided.\")\n",
        "    start_date = get_start_date()\n",
        "    return {\n",
        "        date_str: (start_date + dt.timedelta(days=index)).strftime(\"%d.%m.%Y\")\n",
        "        for index, date_str in enumerate(unique_dates)\n",
        "    }, start_date\n",
        "\n",
        "def replace_dates(value: str, date_mapping: dict[str, str], start_date: dt.date) -> str:\n",
        "    def replacer(match: re.Match[str]) -> str:\n",
        "        token = match.group(0)\n",
        "        if token in PLACEHOLDER_OFFSETS:\n",
        "            offset = PLACEHOLDER_OFFSETS[token]\n",
        "            target = start_date + dt.timedelta(days=offset)\n",
        "            return target.strftime(\"%d.%m.%Y\")\n",
        "        return date_mapping.get(token, token)\n",
        "\n",
        "    return DATE_TOKEN_RE.sub(replacer, value)\n",
        "\n",
        "def update_csv(input_path: Path, suffix: str = \"_today\", days: int = 5) -> Path:\n",
        "    with input_path.open(\"r\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "        reader = csv.DictReader(handle)\n",
        "        if reader.fieldnames is None:\n",
        "            raise ValueError(f\"No header row found in {input_path}.\")\n",
        "        fieldnames = list(reader.fieldnames)\n",
        "        rows = list(reader)\n",
        "\n",
        "    unique_dates = sorted({date for date in extract_dates(rows, fieldnames)}, key=parse_date)\n",
        "    date_mapping, start_date = build_date_mapping(unique_dates, days=days)\n",
        "\n",
        "    updated_rows = [\n",
        "        {key: replace_dates(value, date_mapping, start_date) if value else value for key, value in row.items()}\n",
        "        for row in rows\n",
        "    ]\n",
        "\n",
        "    output_path = input_path.with_name(f\"{input_path.stem}{suffix}{input_path.suffix}\")\n",
        "    with output_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "        writer = csv.DictWriter(handle, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(updated_rows)\n",
        "    return output_path\n",
        "\n",
        "csv_files = [\n",
        "    Path(\"test_data/medweb_test_multiday.csv\"),\n",
        "    Path(\"test_data/medweb_test_multiday_v2.csv\"),\n",
        "    Path(\"test_data/medweb_test_multiday_v3.csv\"),\n",
        "    Path(\"test_data/medweb_test_multiday_v4.csv\"),\n",
        "]\n",
        "\n",
        "for csv_path in csv_files:\n",
        "    output_path = update_csv(csv_path)\n",
        "    print(f\"Wrote {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
