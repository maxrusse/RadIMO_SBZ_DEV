{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update test_data dates to today\\n",
        "\\n",
        "This cell replaces placeholder dates (xx/yy/zz) or existing dates in the CSVs with today and the next two days, then writes `*_today.csv` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import csv\n",
        "import datetime as dt\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "DATE_TOKEN_RE = re.compile(r\\"\\b(\\d{2}\\.\\d{2}\\.\\d{4}|xx\\.xx\\.xxxx|yy\\.yy\\.yyyy|zz\\.zz\\.zzzz)\\b\\")\n",
        "PLACEHOLDER_OFFSETS = {\"xx.xx.xxxx\": 0, \"yy.yy.yyyy\": 1, \"zz.zz.zzzz\": 2}\n",
        "\n",
        "def parse_date(value: str) -> dt.date:\n",
        "    return dt.datetime.strptime(value, \\\"%d.%m.%Y\\\").date()\n",
        "\n",
        "def extract_dates(rows: list[dict[str, str]], fieldnames: list[str]) -> list[str]:\n",
        "    if \"Datum\" in fieldnames:\n",
        "        values = [row[\"Datum\"].strip() for row in rows if row.get(\"Datum\")]\n",
        "    else:\n",
        "        values = []\n",
        "    if not values:\n",
        "        for row in rows:\n",
        "            for value in row.values():\n",
        "                if value:\n",
        "                    values.extend(DATE_TOKEN_RE.findall(value))\n",
        "    return [value for value in values if value not in PLACEHOLDER_OFFSETS]\n",
        "\n",
        "def build_date_mapping(unique_dates: list[str], days: int = 3) -> dict[str, str]:\n",
        "    if len(unique_dates) > days:\n",
        "        raise ValueError(f\"Found {len(unique_dates)} unique dates but only {days} days were provided.\")\n",
        "    today = dt.date.today()\n",
        "    return {\n",
        "        date_str: (today + dt.timedelta(days=index)).strftime(\"%d.%m.%Y\")\n",
        "        for index, date_str in enumerate(unique_dates)\n",
        "    }\n",
        "\n",
        "def replace_dates(value: str, date_mapping: dict[str, str]) -> str:\n",
        "    def replacer(match: re.Match[str]) -> str:\n",
        "        token = match.group(0)\n",
        "        if token in PLACEHOLDER_OFFSETS:\n",
        "            offset = PLACEHOLDER_OFFSETS[token]\n",
        "            target = dt.date.today() + dt.timedelta(days=offset)\n",
        "            return target.strftime(\"%d.%m.%Y\")\n",
        "        return date_mapping.get(token, token)\n",
        "\n",
        "    return DATE_TOKEN_RE.sub(replacer, value)\n",
        "\n",
        "def update_csv(input_path: Path, suffix: str = \"_today\", days: int = 3) -> Path:\n",
        "    with input_path.open(\"r\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "        reader = csv.DictReader(handle)\n",
        "        if reader.fieldnames is None:\n",
        "            raise ValueError(f\"No header row found in {input_path}.\")\n",
        "        fieldnames = list(reader.fieldnames)\n",
        "        rows = list(reader)\n",
        "\n",
        "    unique_dates = sorted({date for date in extract_dates(rows, fieldnames)}, key=parse_date)\n",
        "    date_mapping = build_date_mapping(unique_dates, days=days)\n",
        "\n",
        "    updated_rows = [\n",
        "        {key: replace_dates(value, date_mapping) if value else value for key, value in row.items()}\n",
        "        for row in rows\n",
        "    ]\n",
        "\n",
        "    output_path = input_path.with_name(f\"{input_path.stem}{suffix}{input_path.suffix}\")\n",
        "    with output_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as handle:\n",
        "        writer = csv.DictWriter(handle, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(updated_rows)\n",
        "    return output_path\n",
        "\n",
        "csv_files = [\n",
        "    Path(\"test_data/medweb_test_multiday.csv\"),\n",
        "    Path(\"test_data/medweb_test_multiday_v2.csv\"),\n",
        "]\n",
        "\n",
        "for csv_path in csv_files:\n",
        "    output_path = update_csv(csv_path)\n",
        "    print(f\"Wrote {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
